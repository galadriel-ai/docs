---
title: Memory
---
## What is agent memory?

Agents come with a default memory management system that enhances the experience of ongoing conversations. For example, a Discord agent can remember previous interactions (from messages, tools and errors), ensuring smoother and more natural conversations.

### **Memory components**

- **Past LLM outputs** â€“ Previous responses generated by the language model
- **Actions taken** â€“ The tools or functions the agent has executed
- **Observations** â€“ Feedback or results received after performing an action
- **Errors encountered** â€“ Any failures or issues that occurred

### **How memory is used**

- This information is processed into a structured series of messages.
- These messages serve as input for the LLM, helping it maintain context.
- The agent remembers:
    - Chat history
    - The tools it has used previously
    - Any relevant error logs
- Keeping this memory updated ensures a smooth, conversation-like experience with the agent.

## Adding Memory to your Agent

### Setup

Memory is enabled by default in both [CodeAgent and ToolCallingAgent](https://github.com/galadriel-ai/galadriel/blob/main/galadriel/agent.py#L54-L104) by flagging the `flush_memory` variable to `False`.

### Debug

When the `Runtime` runs in debug mode, it logs the current memory at each new message. To enable debug mode in `Runtime`, set `debug=True`:

```python
my_agent = AgentRuntime(
    inputs=[client],
    outputs=[client],
    agent=chat_agent,
    **debug=True**
)
```

When running in debug mode, the current memory is logged at each new message, as shown in the snippet below:

```python
[INFO] Current agent memory: [{'content': [{'text': 'New task:\n'
                       '\n'
                       '# Task: You are chatting with user_03344 on '
                       'discord. You must reply to the incoming message in the '
                       'voice and style of Elon Musk:\n'
                       'yo\n'
                       '\n'
                       'Be very brief, and concise, add a statement in your '
                       'voice.\n'
                       'Please remember the chat history and use it to answer '
                       'the question.\n',
               'type': 'text'}],
  'role': <MessageRole.USER: 'user'>},
 {'content': [{'text': 'Calling tools:\n'
                       "[{'id': 'call_VfeuzcvGhelSk2B2M9a2qxKy', 'type': "
                       "'function', 'function': {'name': 'final_answer', "
                       '\'arguments\': {\'answer\': "Hey! ðŸš€ What\'s up? How '
                       "can I help accelerate humanity's future today? "
                       'ðŸ”‹âœ¨"}}}]',
               'type': 'text'}],
  'role': <MessageRole.ASSISTANT: 'assistant'>}]
```

### Disable

Memory can be manually disabled as follows:

```python
agent = CodeAgent(flush_memory=True)
```

When `flush_memory=True` is set, memory is not updated or carried over to new tasks, allowing the agent to operate without context from previous interactions. This can be useful for zero-shot tasks and/or when the LLM context size is critical.

## Conclusion

Agent memory plays a crucial role in enabling natural, context-aware interactions. Key takeaways:

- **Enhances responses** â€“ By remembering chat history, tool usage, and error logs, agents can generate more relevant answers
- **Enabled by default** â€“ `AgentRuntime` retains memory across interactions unless manually disabled
- **Debugging support** â€“ When debug mode is enabled (`debug=True`), the agent logs its memory at each step for transparency
- **Manual control** â€“ Memory can be disabled (`flush_memory=True`) for zero-shot tasks or when context size is a concern

By understanding and configuring memory effectively, you can tailor agent behavior to best suit your needs.

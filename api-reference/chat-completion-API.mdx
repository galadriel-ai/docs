---
title: Chat Completion API
description: Tap into Galadriel's LLM inference network. Follows the exact schema as OpenAI's chat completion API.
openapi: post /v1/chat/completions
api: 'POST https://api.galadriel.com/v1/chat/completions'
authMethod: "bearer"
---

<ResponseExample>

```json 200
{
  "id": "id",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?",
        "refusal": null,
        "role": "assistant",
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1728558433,
  "model": "neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": null
}
```

```text stream
data: {"id":"chat-50ad61812fd147158e3776bf89c18698","choices":[{"delta":{"content":"","role":"assistant"},"finish_reason":null,"index":0,"logprobs":null}],"created":1729078303,"model":"neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8","object":"chat.completion.chunk","usage":null}

data: {"id":"chat-50ad61812fd147158e3776bf89c18698","choices":[{"delta":{"content":"Hello"},"finish_reason":null,"index":0,"logprobs":null}],"created":1729078303,"model":"neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8","object":"chat.completion.chunk","usage":null}

...

data: {"id":"chat-50ad61812fd147158e3776bf89c18698","choices":[{"delta":{"content":""},"finish_reason":"stop","index":0,"logprobs":null,"stop_reason":null}],"created":1729078303,"model":"neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8","object":"chat.completion.chunk","usage":null}

data: [DONE]
```

```json 422
{
  "detail": [
    {
      "loc": [
        "<string>"
      ],
      "msg": "<string>",
      "type": "<string>"
    }
  ]
}
```

```json 429
{
  "response": "NOK",
  "error": {
    "status_code": 500,
    "code": "rate_limit_exceeded",
    "message": "Rate limit exceeded"
  }
}
```


```json 503
{
  "response": "NOK",
  "error": {
    "status_code": 503,
    "code": "no_available_inference_nodes",
    "message": "No available inference nodes to process the request."
  }
}
```

```text stream error
event: error
data: {"error": {"message": "No available inference nodes to process the request."}}
```

</ResponseExample>